{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리\n",
    "#### 1-1. 데이터 load \n",
    "- https://github.com/bab2min/corpus/tree/master/sentiment 에서 다운로드한 데이터 다운로드 후 load\n",
    "- columns 이름 추가\n",
    "- label column 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/naver_shopping.txt\", sep = '\\t', encoding = 'utf-8', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  5                                            배공빠르고 굿\n",
       "1  2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
       "2  5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
       "3  2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
       "4  5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['rating', 'Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             Review\n",
       "0       5                                            배공빠르고 굿\n",
       "1       2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
       "2       5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
       "3       2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
       "4       5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_to_label(rating):\n",
    "    if rating >=4 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['y'] = df['rating'].apply(lambda x: rating_to_label(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. 유의어 일원화\n",
    "- 자체적으로 만든 유의어 사전 로딩(txt 파일)\n",
    "- 비슷한 단어들을 하나의 단어로 통일하는 전처리 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../../data/review_synonym_final.txt\", 'r', encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = f.readlines()\n",
    "\n",
    "for idx, l in enumerate(lines):\n",
    "    lines[idx] = l.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dic = {}\n",
    "\n",
    "for idx, l in enumerate(lines):\n",
    "    temp = l.split(',')\n",
    "    lines_dic[temp[0]] = temp[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, wordList in lines_dic.items():\n",
    "    for word in wordList:\n",
    "        df['Review'] = df['Review'].str.replace(word, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. 불용어 사전 편집\n",
    "- \"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\" 활용\n",
    "- EDA 과정에서 평점과 상관없이 빈출된 단어(배송, 구매, 생각, 사용 등) 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
    "stopwords.append('배송')\n",
    "stopwords.append('구매')\n",
    "stopwords.append('생각')\n",
    "stopwords.append('사용')\n",
    "stopwords.append('가격')\n",
    "stopwords.append('제품')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4. 토큰화된 리뷰 컬럼 추가\n",
    "- 명사, 동사, 형용사에 해당하는 2글자 이상의 형태소만 활용하는 토큰화함수 1을 적용한 리뷰 컬럼 생성\n",
    "- 모든 형태소와 이모티콘을 활용하는 토큰화함수 2를 적용한 리뷰 컬럼 생성\n",
    "- 향후 countervectorization, TFIDF vectorization에 사용하는 토큰화함수는 띄어쓰기 기준으로 토큰화하는 간소화된 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "def tokenizer_1(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]')\n",
    "    result = hangul.sub('', text)\n",
    "    okt = Okt()\n",
    "    Okt_morphs = okt.pos(result)\n",
    "    words = []\n",
    "\n",
    "    for word, pos in Okt_morphs:\n",
    "        if pos == 'Adjective' or pos == 'Verb' or pos == 'Noun':\n",
    "            if len(word) > 1 and word not in stopwords:\n",
    "                words.append(word)\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt2 = Okt()\n",
    "\n",
    "def tokenizer_2(text):\n",
    "    tokens_ko = okt2.morphs(text)\n",
    "\n",
    "    result = []\n",
    "    for word in tokens_ko:\n",
    "        if word not in stopwords:\n",
    "            result.append(word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200000it [7:35:35,  7.32it/s] \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "tokenized_1 = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    tokenized_review = tokenizer_1(df.loc[idx, 'Review'])\n",
    "    tokenized_1.append(tokenized_review)\n",
    "\n",
    "df['tokenized_1'] = tokenized_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200000it [07:14, 460.64it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_2 = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    tokenized_review = tokenizer_2(df.loc[idx, 'Review'])\n",
    "    tokenized_2.append(tokenized_review)\n",
    "\n",
    "df['tokenized_2'] = tokenized_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>y</th>\n",
       "      <th>tokenized_1</th>\n",
       "      <th>tokenized_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "      <td>1</td>\n",
       "      <td>배공 빠르고</td>\n",
       "      <td>배공 빠르고 굿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "      <td>0</td>\n",
       "      <td>택배 엉망 놔두고가고</td>\n",
       "      <td>택배 가 엉망 이네 용 저희 집 밑 에 층 에 말 도 없이 놔두고가고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 박음질이 조금 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>아주 좋아요 바지 정말 좋아서 했어요 대박 입니다 박음질 조금 어설프다하긴 편하고 ...</td>\n",
       "      <td>아주 좋아요 바지 정말 좋아서 2 개 더 했어요 이 에 대박 입니다 . 박음질 이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "      <td>0</td>\n",
       "      <td>선물 받아서 전달 했어야 하는 상품 이었는데 머그컵 와서 당황 했습니다 전화했더니 ...</td>\n",
       "      <td>선물 용 으로 빨리 받아서 전달 했어야 하는 상품 이었는데 머그컵 만 와서 당황 했...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "      <td>1</td>\n",
       "      <td>민트 색상 예뻐요 손잡이 도로 되네요</td>\n",
       "      <td>민트 색상 상 예뻐요 . 옆 손잡이 는 거 는 용 도로 도 되네요 ㅎㅎ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             Review  y  \\\n",
       "0       5                                            배공빠르고 굿  1   \n",
       "1       2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고  0   \n",
       "2       5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 박음질이 조금 ...  1   \n",
       "3       2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...  0   \n",
       "4       5                 민트색상상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ  1   \n",
       "\n",
       "                                         tokenized_1  \\\n",
       "0                                             배공 빠르고   \n",
       "1                                        택배 엉망 놔두고가고   \n",
       "2  아주 좋아요 바지 정말 좋아서 했어요 대박 입니다 박음질 조금 어설프다하긴 편하고 ...   \n",
       "3  선물 받아서 전달 했어야 하는 상품 이었는데 머그컵 와서 당황 했습니다 전화했더니 ...   \n",
       "4                               민트 색상 예뻐요 손잡이 도로 되네요   \n",
       "\n",
       "                                         tokenized_2  \n",
       "0                                           배공 빠르고 굿  \n",
       "1             택배 가 엉망 이네 용 저희 집 밑 에 층 에 말 도 없이 놔두고가고  \n",
       "2  아주 좋아요 바지 정말 좋아서 2 개 더 했어요 이 에 대박 입니다 . 박음질 이 ...  \n",
       "3  선물 용 으로 빨리 받아서 전달 했어야 하는 상품 이었는데 머그컵 만 와서 당황 했...  \n",
       "4            민트 색상 상 예뻐요 . 옆 손잡이 는 거 는 용 도로 도 되네요 ㅎㅎ  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/naver_shopping_preprocessed_final.csv\", sep = \",\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating         0\n",
      "Review         0\n",
      "y              0\n",
      "tokenized_1    0\n",
      "tokenized_2    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   rating       200000 non-null  int64 \n",
      " 1   Review       200000 non-null  object\n",
      " 2   y            200000 non-null  int64 \n",
      " 3   tokenized_1  200000 non-null  object\n",
      " 4   tokenized_2  200000 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델링\n",
    "#### 2-1. DTM + GridSearchCV + tokenizer_1\n",
    "* countervectorizer\n",
    "* GridSearchCV\n",
    "* Tokenizer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['y']\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(df['tokenized_1'], y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect1 = CountVectorizer(min_df = 3, ngram_range=(1,2), tokenizer = tokenizer)\n",
    "X_train_vectorized1 = vect1.fit_transform(X_train_texts)\n",
    "X_test_vectorized1 = vect1.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist_DTM_tk1 = [word for word, number in sorted(vect1.vocabulary_.items(), key = lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] END ..............................................C=0.6; total time=   1.6s\n",
      "[CV] END ..............................................C=0.6; total time=   1.5s\n",
      "[CV] END ..............................................C=0.6; total time=   1.3s\n",
      "[CV] END ..............................................C=0.8; total time=   1.8s\n",
      "[CV] END ..............................................C=0.8; total time=   1.8s\n",
      "[CV] END ..............................................C=0.8; total time=   1.7s\n",
      "[CV] END ................................................C=1; total time=   1.9s\n",
      "[CV] END ................................................C=1; total time=   2.3s\n",
      "[CV] END ................................................C=1; total time=   1.7s\n",
      "[CV] END ..............................................C=3.5; total time=   2.2s\n",
      "[CV] END ..............................................C=3.5; total time=   5.7s\n",
      "[CV] END ..............................................C=3.5; total time=   2.9s\n",
      "[CV] END ..............................................C=4.5; total time=   2.9s\n",
      "[CV] END ..............................................C=4.5; total time=   6.6s\n",
      "[CV] END ..............................................C=4.5; total time=   2.5s\n",
      "{'C': 0.6} 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(random_state = 0, solver = 'liblinear', max_iter = 1000)\n",
    "params = { 'C': [0.6, 0.8, 1 , 3.5, 4.5 ] }\n",
    "grid_cv = GridSearchCV(lr , param_grid=params , cv=3 ,scoring='accuracy', verbose=2 )\n",
    "grid_cv.fit(X_train_vectorized1 , y_train)\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_DTM_tk1 = grid_cv.best_estimator_\n",
    "y_pred = best_estimator_DTM_tk1.predict(X_test_vectorized1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.898\n",
      "Precision : 0.902\n",
      "Recall : 0.893\n",
      "F1 : 0.897\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('saved_CounterVectorizer_tk1_final.pickle','wb') as fw:\n",
    "    pickle.dump(vect1, fw)\n",
    "\n",
    "with open('DTM_tokenizer1_gridsearch_done_final.pickle','wb') as fw:\n",
    "    pickle.dump(best_estimator_DTM_tk1, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)\n",
      "맛있어요(2.721)\n",
      "만족해요(2.508)\n",
      "최고(2.469)\n",
      "튼튼합니다(2.442)\n",
      "맛있고(2.430)\n",
      "예뻐요(2.386)\n",
      "좋아요(2.374)\n",
      "잘쓰고있어요(2.220)\n",
      "편해요(2.216)\n",
      "튼튼해요(2.167)\n",
      "빨랐고(2.159)\n",
      "빠르고(2.099)\n",
      "튼튼하네요(2.093)\n",
      "편리합니다(2.092)\n",
      "좋았습니다(2.090)\n",
      "에드(2.076)\n",
      "딱좋아요(2.066)\n",
      "귀엽다(2.057)\n",
      "이뻐용(2.048)\n",
      "만족합니다(2.037)\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_estimator_DTM_tk1.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:20]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist_DTM_tk1[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)\n",
      "최악(-3.543)\n",
      "실망(-3.013)\n",
      "비추(-2.927)\n",
      "실망했어요(-2.735)\n",
      "맛있어요 맛있어요(-2.677)\n",
      "안좋아요(-2.635)\n",
      "약해요(-2.544)\n",
      "좋아요 좋아요(-2.530)\n",
      "맛없어요(-2.495)\n",
      "다시는(-2.474)\n",
      "별로(-2.465)\n",
      "떨어집니다(-2.406)\n",
      "엉망(-2.364)\n",
      "느려요(-2.331)\n",
      "불편해요(-2.312)\n",
      "다신(-2.277)\n",
      "떨어져요(-2.273)\n",
      "그래요(-2.254)\n",
      "심하네요(-2.247)\n",
      "불편합니다(-2.239)\n"
     ]
    }
   ],
   "source": [
    "print('\\n부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-20:][::-1]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist_DTM_tk1[word_num], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. TFIDF + GridSearchCV + tokenizer_1\n",
    "* TFIDF\n",
    "* GridSearchCV\n",
    "* Tokenizer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer1 = TfidfVectorizer(ngram_range=(1,2), min_df = 3, max_df = 0.9, tokenizer = tokenizer)\n",
    "tfidf_vectorizer1.fit(X_train_texts)\n",
    "tfidf_matrix_train = tfidf_vectorizer1.transform(X_train_texts)\n",
    "tfidf_matrix_test = tfidf_vectorizer1.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist_TFIDF_tk1 = [word for word, number in sorted(tfidf_vectorizer1.vocabulary_.items(), key = lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] END ..............................................C=0.6; total time=   0.4s\n",
      "[CV] END ..............................................C=0.6; total time=   0.3s\n",
      "[CV] END ..............................................C=0.6; total time=   0.3s\n",
      "[CV] END ..............................................C=0.8; total time=   0.3s\n",
      "[CV] END ..............................................C=0.8; total time=   0.3s\n",
      "[CV] END ..............................................C=0.8; total time=   0.3s\n",
      "[CV] END ................................................C=1; total time=   0.4s\n",
      "[CV] END ................................................C=1; total time=   0.4s\n",
      "[CV] END ................................................C=1; total time=   0.4s\n",
      "[CV] END ..............................................C=3.5; total time=   0.5s\n",
      "[CV] END ..............................................C=3.5; total time=   0.7s\n",
      "[CV] END ..............................................C=3.5; total time=   0.7s\n",
      "[CV] END ..............................................C=4.5; total time=   0.8s\n",
      "[CV] END ..............................................C=4.5; total time=   0.7s\n",
      "[CV] END ..............................................C=4.5; total time=   0.7s\n",
      "{'C': 3.5} 0.897\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 0, solver = 'liblinear', max_iter = 1000)\n",
    "params = { 'C': [0.6, 0.8, 1 ,3.5, 4.5 ] }\n",
    "grid_cv = GridSearchCV(lr , param_grid=params , cv=3 ,scoring='accuracy', verbose=2 )\n",
    "grid_cv.fit(tfidf_matrix_train , y_train)\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_TFIDF_tk1 = grid_cv.best_estimator_\n",
    "y_pred = best_estimator_TFIDF_tk1.predict(tfidf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.899\n",
      "Precision : 0.902\n",
      "Recall : 0.894\n",
      "F1 : 0.898\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_TfidfVectorizer_tk1_final.pickle','wb') as fw:\n",
    "    pickle.dump(tfidf_vectorizer1, fw)\n",
    "\n",
    "with open('TFIDF_tokenizer1_gridsearch_done_final.pickle','wb') as fw:\n",
    "    pickle.dump(best_estimator_TFIDF_tk1, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)\n",
      "좋아요(10.702)\n",
      "맛있어요(9.361)\n",
      "예뻐요(9.091)\n",
      "최고(8.217)\n",
      "만족해요(8.067)\n",
      "빠르고(7.594)\n",
      "튼튼하고(6.309)\n",
      "편해요(5.784)\n",
      "맛있고(5.573)\n",
      "빨랐고(5.438)\n",
      "편하고(5.317)\n",
      "믿고(5.283)\n",
      "항상(5.266)\n",
      "괜찮네요(5.265)\n",
      "했어요(5.248)\n",
      "좋았습니다(5.120)\n",
      "강추(5.120)\n",
      "확실히(5.064)\n",
      "걱정 했는데(5.050)\n",
      "만족(5.013)\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_estimator_TFIDF_tk1.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:20]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist_TFIDF_tk1[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)\n",
      "실망(-12.152)\n",
      "별로(-11.179)\n",
      "반품(-10.975)\n",
      "최악(-10.473)\n",
      "비추(-8.710)\n",
      "그렇다(-7.477)\n",
      "환불(-7.305)\n",
      "엉망(-7.207)\n",
      "불편해요(-7.169)\n",
      "다시는(-6.969)\n",
      "실망했어요(-6.916)\n",
      "안좋아요(-6.889)\n",
      "다신(-6.269)\n",
      "불편합니다(-6.155)\n",
      "떨어집니다(-6.103)\n",
      "맛없어요(-6.013)\n",
      "약해요(-5.918)\n",
      "떨어져요(-5.892)\n",
      "심하네요(-5.812)\n",
      "아니네요(-5.805)\n"
     ]
    }
   ],
   "source": [
    "print('\\n부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-20:][::-1]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist_TFIDF_tk1[word_num], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3. DTM + GridSearchCV + tokenizer_2\n",
    "* countervectorizer\n",
    "* GridSearchCV\n",
    "* Tokenizer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(df['tokenized_2'], y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect2 = CountVectorizer(min_df = 3, ngram_range=(1,2), tokenizer = tokenizer)\n",
    "X_train_vectorized2 = vect2.fit_transform(X_train_texts)\n",
    "X_test_vectorized2 = vect2.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist_DTM_tk2 = [word for word, number in sorted(vect2.vocabulary_.items(), key = lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] END ..............................................C=0.6; total time=   4.8s\n",
      "[CV] END ..............................................C=0.6; total time=   4.5s\n",
      "[CV] END ..............................................C=0.6; total time=   4.2s\n",
      "[CV] END ..............................................C=0.8; total time=   5.3s\n",
      "[CV] END ..............................................C=0.8; total time=   4.8s\n",
      "[CV] END ..............................................C=0.8; total time=   4.5s\n",
      "[CV] END ................................................C=1; total time=   8.3s\n",
      "[CV] END ................................................C=1; total time=   4.0s\n",
      "[CV] END ................................................C=1; total time=   4.6s\n",
      "[CV] END ..............................................C=3.5; total time=  14.7s\n",
      "[CV] END ..............................................C=3.5; total time=   8.9s\n",
      "[CV] END ..............................................C=3.5; total time=   7.1s\n",
      "[CV] END ..............................................C=4.5; total time=  11.8s\n",
      "[CV] END ..............................................C=4.5; total time=   8.9s\n",
      "[CV] END ..............................................C=4.5; total time=  14.9s\n",
      "{'C': 0.6} 0.915\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 0, solver = 'liblinear', max_iter = 1000)\n",
    "params = { 'C': [0.6, 0.8, 1 ,3.5, 4.5 ] }\n",
    "grid_cv = GridSearchCV(lr , param_grid=params , cv=3 ,scoring='accuracy', verbose=2 )\n",
    "grid_cv.fit(X_train_vectorized2 , y_train)\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.915\n",
      "Precision : 0.914\n",
      "Recall : 0.915\n",
      "F1 : 0.914\n"
     ]
    }
   ],
   "source": [
    "best_estimator_DTM_tk2 = grid_cv.best_estimator_\n",
    "y_pred = best_estimator_DTM_tk2.predict(X_test_vectorized2)\n",
    "\n",
    "print(\"accuracy: %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_CounterVectorizer_tk2_final.pickle','wb') as fw:\n",
    "    pickle.dump(vect2, fw)\n",
    "\n",
    "with open('DTM_tokenizer2_gridsearch_done_final.pickle','wb') as fw:\n",
    "    pickle.dump(best_estimator_DTM_tk2, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)\n",
      "맛있어요(2.501)\n",
      "만족해요(2.293)\n",
      "맛있고(2.273)\n",
      "예뻐요(2.170)\n",
      "최고(2.119)\n",
      "튼튼합니다(2.079)\n",
      "좋아요(2.064)\n",
      "좋았습니다(2.062)\n",
      "잘 왔어요(1.957)\n",
      "튼튼해요(1.946)\n",
      "편합니다(1.898)\n",
      "잘쓰고있어요(1.898)\n",
      "편해요(1.895)\n",
      "촉촉하고(1.856)\n",
      "이뻐용(1.840)\n",
      "빠르고(1.814)\n",
      "편리합니다(1.805)\n",
      "딱좋아요(1.791)\n",
      "괜찮네요(1.778)\n",
      "튼튼하네요(1.744)\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_estimator_DTM_tk2.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:20]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist_DTM_tk2[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)\n",
      "최악(-3.308)\n",
      "실망(-2.755)\n",
      "맛있어요 맛있어요(-2.552)\n",
      "비추(-2.536)\n",
      "불편해요(-2.355)\n",
      "좋아요 좋아요(-2.277)\n",
      "떨어져요(-2.228)\n",
      "실망했어요(-2.177)\n",
      "엉망(-2.167)\n",
      "별로(-2.090)\n",
      "안좋아요(-2.073)\n",
      "맛없어요(-2.052)\n",
      "불만족(-2.038)\n",
      "불편합니다(-2.034)\n",
      "불편하네요(-2.022)\n",
      "불만(-1.933)\n",
      "아니네요(-1.930)\n",
      "좋아요 좋(-1.915)\n",
      "환불(-1.898)\n",
      "심하네요(-1.868)\n"
     ]
    }
   ],
   "source": [
    "print('\\n부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-20:][::-1]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist_DTM_tk2[word_num], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-4. TFIDF + GridSearchCV + tokenizer_2\n",
    "* TFIDF\n",
    "* GridSearchCV\n",
    "* Tokenizer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer2 = TfidfVectorizer(ngram_range=(1,2), min_df = 3, max_df = 0.9, tokenizer = tokenizer)\n",
    "tfidf_vectorizer2.fit(X_train_texts)\n",
    "tfidf_matrix_train = tfidf_vectorizer2.transform(X_train_texts)\n",
    "tfidf_matrix_test = tfidf_vectorizer2.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist_TFIDF_tk2 = [word for word, number in sorted(vect2.vocabulary_.items(), key = lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "{'C': 3.5} 0.916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(random_state = 0, solver = 'liblinear', max_iter = 1000)\n",
    "params = { 'C': [0.6, 0.8, 1 ,3.5, 4.5 ] }\n",
    "grid_cv = GridSearchCV(lr , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
    "grid_cv.fit(tfidf_matrix_train, y_train)\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.915\n",
      "Precision : 0.918\n",
      "Recall : 0.911\n",
      "F1 : 0.915\n"
     ]
    }
   ],
   "source": [
    "best_estimator_TFIDF_tk2 = grid_cv.best_estimator_\n",
    "y_pred = best_estimator_TFIDF_tk2.predict(tfidf_matrix_test)\n",
    "print(\"accuracy: %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_TfidfVectorizer_tk2_final.pickle','wb') as fw:\n",
    "    pickle.dump(tfidf_vectorizer2, fw)\n",
    "\n",
    "with open('TFIDF_tokenizer2_gridsearch_done_final.pickle','wb') as fw:\n",
    "    pickle.dump(best_estimator_TFIDF_tk2, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)\n",
      "좋아요(14.766)\n",
      "맛있어요(11.234)\n",
      "예뻐요(10.507)\n",
      "만족해요(9.901)\n",
      "최고(9.129)\n",
      "^^(8.102)\n",
      "!(7.214)\n",
      "잘(7.093)\n",
      "빠르고(7.019)\n",
      "ㅎㅎ(6.838)\n",
      "편해요(6.291)\n",
      "만족(6.256)\n",
      "확실히(6.207)\n",
      "좋았습니다(6.178)\n",
      "했어요(6.100)\n",
      "믿고(6.079)\n",
      "튼튼하고(5.904)\n",
      "괜찮네요(5.872)\n",
      "좋은(5.868)\n",
      "항상(5.816)\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_estimator_TFIDF_tk2.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:20]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist_TFIDF_tk2[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 단어 Top 10 (낮은 평점과 상관관계가 강한 단어들)\n",
      "실망(-12.320)\n",
      "최악(-10.563)\n",
      "반품(-10.202)\n",
      "그렇다(-9.714)\n",
      "별로(-9.107)\n",
      "비추(-8.881)\n",
      "불편해요(-8.360)\n",
      "ㅡㅡ(-8.163)\n",
      "못(-7.462)\n",
      "엉망(-7.084)\n",
      "빠르고 좋아요(-6.747)\n",
      "떨어져요(-6.694)\n",
      "환불(-6.693)\n",
      "돈(-6.501)\n",
      "불량(-6.429)\n",
      "...(-6.365)\n",
      "불편하네요(-6.158)\n",
      "안좋아요(-6.156)\n",
      "안(-6.149)\n",
      "아니네요(-6.128)\n"
     ]
    }
   ],
   "source": [
    "print('\\n부정적인 단어 Top 10 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-20:][::-1]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist_TFIDF_tk2[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('ds_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8980de4a27bf89e986bf71fe1fbb5d572934705242a5da409cea5b4049808f61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
