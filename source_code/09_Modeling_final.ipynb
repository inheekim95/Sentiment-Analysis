{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenized된 리뷰 데이터 전처리 보완하기\n",
    "* 불러오기\n",
    "* null 값 있는 컬럼 제거하기\n",
    "* 유의어 일원화 보완\n",
    "* 갱신된 불용어 사전 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Review</th>\n",
       "      <th>y</th>\n",
       "      <th>tokenized_1</th>\n",
       "      <th>tokenized_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>생각외로 모기가 안잡혀요</td>\n",
       "      <td>0</td>\n",
       "      <td>생각 외로 모기 잡혀요</td>\n",
       "      <td>생각 외로 모기 잡혀요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>고구마가 외이케 말랏나요 저나하려다 바빠깜팍 햇는데 서너번 주문한적잇는데 이런적업엇...</td>\n",
       "      <td>0</td>\n",
       "      <td>고구마 외이케 말랏나 나하 바빠깜팍 는데 한적 잇는데 적업 는데 사이즈 정도 아니라...</td>\n",
       "      <td>고구마 외이케 말랏나 나하 려 바빠깜팍 햇 는데 서너 번 문 한적 잇는데 적업 엇 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>(바코드가 왜 손상되서 오는건지 알려주세요) 10년 넘게 써오던 제품이라 항상 만족...</td>\n",
       "      <td>0</td>\n",
       "      <td>바코드 손상 되서 알려주세요 넘게 써오던 제품 항상 만족합니다</td>\n",
       "      <td>( 바코드 손상 되서 오는 건 알려주세요 ) 10년 넘게 써오던 제품 이라 항상 만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5</td>\n",
       "      <td>대용량 박스 사이즈 잘 체크하고 사세요 많다 큽니다</td>\n",
       "      <td>1</td>\n",
       "      <td>용량 박스 사이즈 체크 사세요 많다 큽니다</td>\n",
       "      <td>용량 박스 사이즈 잘 체크 하고 사세요 많다 큽니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>4</td>\n",
       "      <td>시원하구 좋아용!!</td>\n",
       "      <td>1</td>\n",
       "      <td>시원하구 좋아용</td>\n",
       "      <td>시원하구 좋아용 !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5</td>\n",
       "      <td>제품주 좋지만 특히 배송날짜 칼이네요 이사간날 정확하게 배달 설치해주시구 감사합니다~~</td>\n",
       "      <td>1</td>\n",
       "      <td>제품 좋지만 배송 날짜 이사 정확하게 배달 설치 해주시구 감사합니다</td>\n",
       "      <td>제품 좋지만 특히 배송 날짜 칼 이네 이사 간 날 정확하게 배달 설치 해주시구 감사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5</td>\n",
       "      <td>늘 쓰던것~~여름이라 그런지 지속력이 좀떨어지네요ㅜ</td>\n",
       "      <td>1</td>\n",
       "      <td>쓰던것 여름 그런지 지속 떨어지네요</td>\n",
       "      <td>늘 쓰던것 ~~ 여름 이라 그런지 지속 력 떨어지네요 ㅜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5</td>\n",
       "      <td>가격이 저렴하다합니다 ㅎㅎㅎ</td>\n",
       "      <td>1</td>\n",
       "      <td>가격 저렴하다 합니다</td>\n",
       "      <td>가격 저렴하다 합니다 ㅎㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>상품가치 없는크기를 보내셨어요 한입사이즈크기에 3/1은 상했구요 이건좀 아니다싶네요...</td>\n",
       "      <td>0</td>\n",
       "      <td>상품 가치 없는 크기 보내셨어요 입사 크기 했구요 이건 아니다싶네요 정가 할인 크던데</td>\n",
       "      <td>상품 가치 없는 크기 보내셨어요 입사 크기 3/1 은 했구요 이건 아니다싶네요 정가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2</td>\n",
       "      <td>쓸데가 하나없음 효과일도없음</td>\n",
       "      <td>0</td>\n",
       "      <td>쓸데가 없음 효과 일도 없음</td>\n",
       "      <td>쓸데가 없음 효과 일도 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4</td>\n",
       "      <td>저렴하다하게 받아서 기분은좋아요 근데 가방에 실리콘 같은게 좀 묻어있더라구요.. 그...</td>\n",
       "      <td>1</td>\n",
       "      <td>저렴하다하게 받아서 기분 좋아요 가방 실리콘 같은게 묻어있더라구요 괜찬 같아요</td>\n",
       "      <td>저렴하다하게 받아서 기분 은 좋아요 근데 가방 실리콘 같은게 묻어있더라구요 .. 말...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>5</td>\n",
       "      <td>빠른배송감사합니다. 역시 헤라가 짱입니다~^^</td>\n",
       "      <td>1</td>\n",
       "      <td>빠른 배송 감사합니다 역시 헤라 입니다</td>\n",
       "      <td>빠른 배송 감사합니다 . 역시 헤라 짱 입니다 ~^^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>5</td>\n",
       "      <td>받자마자 아이랑 같이 아이스아이보리 만들어먹었는데 실리콘으로 되어서 빼기도 편하고 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>받자마자 아이스 아이보리 만들어 먹었는데 실리콘 되어서 빼기 편하고 좋았어요</td>\n",
       "      <td>받자마자 랑 아이스 아이보리 만들어 먹었는데 실리콘 되어서 빼기 편하고 좋았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>어이가없네요 셈플한개가 비어서 왔네요</td>\n",
       "      <td>0</td>\n",
       "      <td>없네요 비어 왔네요</td>\n",
       "      <td>없네요 셈 플 비어 서 왔네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2</td>\n",
       "      <td>작업하기까다로움 효과도 체감안됨</td>\n",
       "      <td>0</td>\n",
       "      <td>작업 하기 까다로 효과 체감 안됨</td>\n",
       "      <td>작업 하기 까다로 움 효과 체감 안됨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4</td>\n",
       "      <td>만족합니다. 날씬하다핏 아닌 레귤러네요</td>\n",
       "      <td>1</td>\n",
       "      <td>만족합니다 날씬하다 아닌 레귤러네</td>\n",
       "      <td>만족합니다 . 날씬하다 핏 아닌 레귤러네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5</td>\n",
       "      <td>왜 승무원 스프레이라고하는지 알겠네요 짱이에요. 흡수력 광택 @@</td>\n",
       "      <td>1</td>\n",
       "      <td>승무원 스프레이 하는지 알겠네요 흡수 광택</td>\n",
       "      <td>승무원 스프레이 라고 하는지 알겠네요 짱 이에요 . 흡수 력 광택 @@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5</td>\n",
       "      <td>연어초밥, 연어장 만들어 먹었는데 너무 맛있어요! 내일은 연어 스테이크랑 까나페 해...</td>\n",
       "      <td>1</td>\n",
       "      <td>연어초밥 연어 만들어 먹었는데 맛있어요 내일 연어 스테이크 까나페 먹으려고 합니다</td>\n",
       "      <td>연어초밥 , 연어 장 만들어 먹었는데 너무 맛있어요 ! 내일 은 연어 스테이크 랑 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5</td>\n",
       "      <td>상판이 조금 약하긴한데 일부러 누르지 않는한 크고 좋아요.</td>\n",
       "      <td>1</td>\n",
       "      <td>판이 약하긴한데 일부러 누르지 않는한 크고 좋아요</td>\n",
       "      <td>판이 약하긴한데 일부러 누르지 않는한 크고 좋아요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5</td>\n",
       "      <td>시원해서 잘쓸거같아요 여름에!</td>\n",
       "      <td>1</td>\n",
       "      <td>시원해서 잘쓸거 같아요 여름</td>\n",
       "      <td>시원해서 잘쓸거 같아요 여름 !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Score                                             Review  y  \\\n",
       "100      1                                      생각외로 모기가 안잡혀요  0   \n",
       "101      2  고구마가 외이케 말랏나요 저나하려다 바빠깜팍 햇는데 서너번 주문한적잇는데 이런적업엇...  0   \n",
       "102      2  (바코드가 왜 손상되서 오는건지 알려주세요) 10년 넘게 써오던 제품이라 항상 만족...  0   \n",
       "103      5                       대용량 박스 사이즈 잘 체크하고 사세요 많다 큽니다  1   \n",
       "104      4                                         시원하구 좋아용!!  1   \n",
       "105      5   제품주 좋지만 특히 배송날짜 칼이네요 이사간날 정확하게 배달 설치해주시구 감사합니다~~  1   \n",
       "106      5                       늘 쓰던것~~여름이라 그런지 지속력이 좀떨어지네요ㅜ  1   \n",
       "107      5                                    가격이 저렴하다합니다 ㅎㅎㅎ  1   \n",
       "108      1  상품가치 없는크기를 보내셨어요 한입사이즈크기에 3/1은 상했구요 이건좀 아니다싶네요...  0   \n",
       "109      2                                    쓸데가 하나없음 효과일도없음  0   \n",
       "110      4  저렴하다하게 받아서 기분은좋아요 근데 가방에 실리콘 같은게 좀 묻어있더라구요.. 그...  1   \n",
       "111      5                          빠른배송감사합니다. 역시 헤라가 짱입니다~^^  1   \n",
       "112      5  받자마자 아이랑 같이 아이스아이보리 만들어먹었는데 실리콘으로 되어서 빼기도 편하고 ...  1   \n",
       "113      1                               어이가없네요 셈플한개가 비어서 왔네요  0   \n",
       "114      2                                  작업하기까다로움 효과도 체감안됨  0   \n",
       "115      4                              만족합니다. 날씬하다핏 아닌 레귤러네요  1   \n",
       "116      5               왜 승무원 스프레이라고하는지 알겠네요 짱이에요. 흡수력 광택 @@  1   \n",
       "117      5  연어초밥, 연어장 만들어 먹었는데 너무 맛있어요! 내일은 연어 스테이크랑 까나페 해...  1   \n",
       "118      5                   상판이 조금 약하긴한데 일부러 누르지 않는한 크고 좋아요.  1   \n",
       "119      5                                   시원해서 잘쓸거같아요 여름에!  1   \n",
       "\n",
       "                                           tokenized_1  \\\n",
       "100                                       생각 외로 모기 잡혀요   \n",
       "101  고구마 외이케 말랏나 나하 바빠깜팍 는데 한적 잇는데 적업 는데 사이즈 정도 아니라...   \n",
       "102                 바코드 손상 되서 알려주세요 넘게 써오던 제품 항상 만족합니다   \n",
       "103                            용량 박스 사이즈 체크 사세요 많다 큽니다   \n",
       "104                                           시원하구 좋아용   \n",
       "105              제품 좋지만 배송 날짜 이사 정확하게 배달 설치 해주시구 감사합니다   \n",
       "106                                쓰던것 여름 그런지 지속 떨어지네요   \n",
       "107                                        가격 저렴하다 합니다   \n",
       "108    상품 가치 없는 크기 보내셨어요 입사 크기 했구요 이건 아니다싶네요 정가 할인 크던데   \n",
       "109                                    쓸데가 없음 효과 일도 없음   \n",
       "110        저렴하다하게 받아서 기분 좋아요 가방 실리콘 같은게 묻어있더라구요 괜찬 같아요   \n",
       "111                              빠른 배송 감사합니다 역시 헤라 입니다   \n",
       "112         받자마자 아이스 아이보리 만들어 먹었는데 실리콘 되어서 빼기 편하고 좋았어요   \n",
       "113                                         없네요 비어 왔네요   \n",
       "114                                 작업 하기 까다로 효과 체감 안됨   \n",
       "115                                 만족합니다 날씬하다 아닌 레귤러네   \n",
       "116                            승무원 스프레이 하는지 알겠네요 흡수 광택   \n",
       "117      연어초밥 연어 만들어 먹었는데 맛있어요 내일 연어 스테이크 까나페 먹으려고 합니다   \n",
       "118                        판이 약하긴한데 일부러 누르지 않는한 크고 좋아요   \n",
       "119                                    시원해서 잘쓸거 같아요 여름   \n",
       "\n",
       "                                           tokenized_2  \n",
       "100                                       생각 외로 모기 잡혀요  \n",
       "101  고구마 외이케 말랏나 나하 려 바빠깜팍 햇 는데 서너 번 문 한적 잇는데 적업 엇 ...  \n",
       "102  ( 바코드 손상 되서 오는 건 알려주세요 ) 10년 넘게 써오던 제품 이라 항상 만...  \n",
       "103                       용량 박스 사이즈 잘 체크 하고 사세요 많다 큽니다  \n",
       "104                                        시원하구 좋아용 !!  \n",
       "105  제품 좋지만 특히 배송 날짜 칼 이네 이사 간 날 정확하게 배달 설치 해주시구 감사...  \n",
       "106                    늘 쓰던것 ~~ 여름 이라 그런지 지속 력 떨어지네요 ㅜ  \n",
       "107                                    가격 저렴하다 합니다 ㅎㅎㅎ  \n",
       "108  상품 가치 없는 크기 보내셨어요 입사 크기 3/1 은 했구요 이건 아니다싶네요 정가...  \n",
       "109                                    쓸데가 없음 효과 일도 없음  \n",
       "110  저렴하다하게 받아서 기분 은 좋아요 근데 가방 실리콘 같은게 묻어있더라구요 .. 말...  \n",
       "111                      빠른 배송 감사합니다 . 역시 헤라 짱 입니다 ~^^  \n",
       "112       받자마자 랑 아이스 아이보리 만들어 먹었는데 실리콘 되어서 빼기 편하고 좋았어요  \n",
       "113                                   없네요 셈 플 비어 서 왔네요  \n",
       "114                               작업 하기 까다로 움 효과 체감 안됨  \n",
       "115                             만족합니다 . 날씬하다 핏 아닌 레귤러네  \n",
       "116            승무원 스프레이 라고 하는지 알겠네요 짱 이에요 . 흡수 력 광택 @@  \n",
       "117  연어초밥 , 연어 장 만들어 먹었는데 너무 맛있어요 ! 내일 은 연어 스테이크 랑 ...  \n",
       "118                      판이 약하긴한데 일부러 누르지 않는한 크고 좋아요 .  \n",
       "119                                  시원해서 잘쓸거 같아요 여름 !  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/naver_shopping_tokenized_review.csv\", encoding ='utf-8', index_col = 0)\n",
    "df[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score            0\n",
       "Review           0\n",
       "y                0\n",
       "tokenized_1    428\n",
       "tokenized_2     15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score          0\n",
       "Review         0\n",
       "y              0\n",
       "tokenized_1    0\n",
       "tokenized_2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['tokenized_1'].notnull() & df['tokenized_2'].notnull()]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['만족합니다','만족스럽습니다','만족스럽네요','만족합니다','만족스러워요']\n",
    "change = '만족해요'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['좋구요','좋네요','좋습니다','좋아해요','좋아합니다','좋아요요']\n",
    "change = '좋아요'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['안좋아요요']\n",
    "change = '안좋아요'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['에드', '맘에듭니']\n",
    "change = '마음에 듭니다'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['좋아여', '좋아용','좋아하시네요','좋아요하시네요','좋아요요']\n",
    "change = '좋아요'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['맛있었어요']\n",
    "change = '맛있어요'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['예쁘다','이쁘고','예쁘고']\n",
    "change = '예뻐요'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['좋았어요','좋으네요']\n",
    "change = '좋아요'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = ['느리네요','느리고','느려서']\n",
    "change = '느려요'\n",
    "\n",
    "for word in wordList:\n",
    "    df['tokenized_1'] = df['tokenized_1'].str.replace(word, change, regex = True)\n",
    "    df['tokenized_2'] = df['tokenized_2'].str.replace(word, change, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
    "# temp = []\n",
    "# for s in stopwords:\n",
    "#     temp.append(s[0])\n",
    "\n",
    "f = open(\"../../data/stopwords_self_improved.txt\", 'r', encoding= 'utf-8')\n",
    "\n",
    "lines = f.readlines()\n",
    "for idx, l in enumerate(lines):\n",
    "    lines[idx] = l.strip()\n",
    "\n",
    "stopwords = []\n",
    "for l in lines:\n",
    "    stopwords.append(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [04:18<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "for stopword in tqdm(stopwords):\n",
    "    df.replace(stopword, '', regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/naver_shopping_tokenized_review_improved.csv\", sep = \",\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰화 함수 정의\n",
    "* 원래는 CounterVectorizer나 TFIDF 하이퍼파라미터에 해당 tokenizer_1, tokenizer_2 함수를 tokenizer로 지정하는 방법이 기본적인 방법\n",
    "* 시간을 효율적으로 쓰기 위해 tokenizer_1, tokenizer_2 함수를 적용한 컬럼 tokenized_1, tokenized_2를 df에 추가함\n",
    "* 명사, 형용사, 동사 + 1글자 이상만 추출하는 경우 - tokenized_1 리뷰 데이터 활용\n",
    "* 형태소 모두 사용 - tokenized_2 리뷰 데이터 활용\n",
    "* vectorized 클래스에 들어갈 tokenizer는 띄어쓰기 기준으로 split하는 기능만 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화된 데이터 프레임 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Review</th>\n",
       "      <th>y</th>\n",
       "      <th>tokenized_1</th>\n",
       "      <th>tokenized_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>5</td>\n",
       "      <td>지방이라서 이 늦을줄 알았는데 도 빠르고 제품도 생각한것처럼 예쁘고 따갑다끔 특히나...</td>\n",
       "      <td>1</td>\n",
       "      <td>지방  늦을줄 알았는데  빠르고 제품 생각 예뻐요 따갑다  기사 친절하셔서 좋아요</td>\n",
       "      <td>지방 이라서  늦을줄 알았는데  빠르고 제품 생각 처럼 예뻐요 따갑다 끔 특히  기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>상품은 늘 쓰던거라 했는데요 제조일자 6개월이상 된거 보내주셨네요 기분 나쁩니다</td>\n",
       "      <td>0</td>\n",
       "      <td>상품 쓰던거라  했는데요 제조 일자 개월 된거 보내주셨네요 기분 나쁩니다</td>\n",
       "      <td>상품 은 늘 쓰던거라  했는데요 제조 일자 6 개월 된거 보내주셨네요 기분 나쁩니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>고들빼기라 되있는데 깻잎이?? 제가 깻잎을 좋아하고 가격도 비슷하고 귀차나서 다시 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>고들빼기 되있는데 깻잎 깻잎 좋아요하고 가격 비슷하고 나서 다시 환불 교환 요청 합...</td>\n",
       "      <td>고들빼기 되있는데 깻잎 ?? 깻잎 좋아요하고 가격 비슷하고 귀 나서 다시 환불 이나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2</td>\n",
       "      <td>붓기 넘넘 잘빧아요</td>\n",
       "      <td>0</td>\n",
       "      <td>붓기 잘빧아</td>\n",
       "      <td>붓기 넘 넘 잘빧아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2</td>\n",
       "      <td>물건을 얼려놓으면 앞 다쏠리고 힘아리가 도 없네요</td>\n",
       "      <td>0</td>\n",
       "      <td>물건 얼려놓으면 쏠리고 아리 없네요</td>\n",
       "      <td>물건 얼려놓으면 쏠리고 아리 없네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2</td>\n",
       "      <td>신맛이 나요.. 무친지 좀 오래된듯.. 산거 후회합니다. 다 버려야 할듯</td>\n",
       "      <td>0</td>\n",
       "      <td>신맛 무친지 오래된듯 산거 후회 합니다 버려야 할듯</td>\n",
       "      <td>신맛 나요 .. 무친지 오래된듯 .. 산거 후회 합니다 . 버려야 할듯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2</td>\n",
       "      <td>물빠짐 물빠짐 심합니다 실보프라기도 심해서 한참 제게했고 중간중간 올플림도 있어요 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>빠짐 빠짐 심합니다 실보 프라 기도 심해서 한참 했고 중간 중간 있어요 가격 별로 다예</td>\n",
       "      <td>빠짐 빠짐 심합니다 실보 프라 기도 심해서 한참 했고 중간 중간 올 플 림 있어요 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>5</td>\n",
       "      <td>소리도 잘나오고 가성비 정말 좋아요 드라이브 기능도 있어서 너무 만족</td>\n",
       "      <td>1</td>\n",
       "      <td>소리 잘나오고 가성 정말 좋아요 드라이브 기능 있어서 만족</td>\n",
       "      <td>소리 잘나오고 가성 정말 좋아요 드라이브 기능 있어서 너무 만족</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>정전기 대박.... 기장가 긴건 내 키가 작아서라고쳐도 정전기는 왜이렇게 심한건지 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>정전기 대박 기장 긴건 작아 서라고 쳐도 정전기 심한 건지 만지기만 하면 따닥따다닥...</td>\n",
       "      <td>정전기 대박 .... 기장 긴건 내 키 작아 서라고 쳐도 정전기 는 이렇게 심한 건...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>5</td>\n",
       "      <td>맛있어요 고급스러워보입니다</td>\n",
       "      <td>1</td>\n",
       "      <td>맛있어요 고급스러워 보입니다</td>\n",
       "      <td>맛있어요 고급스러워 보입니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>5</td>\n",
       "      <td>좋아요 아이 연습용 했습니다 저는 바이올린은 아예 몰라서 유튜브영상 송진바르는법 이...</td>\n",
       "      <td>1</td>\n",
       "      <td>좋아요 연습  했습니다 바이올린 아예 몰라서 유튜브 영상 송진 바르는 튜닝법 검색 ...</td>\n",
       "      <td>좋아요 연습 용  했습니다 는 바이올린 은 아예 몰라서 유튜브 영상 송진 바르는 법...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>5</td>\n",
       "      <td>열전달도잘괴고좋아요</td>\n",
       "      <td>1</td>\n",
       "      <td>열전달 괴고 좋아요</td>\n",
       "      <td>열전달 잘 괴고 좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1</td>\n",
       "      <td>너무 크네요 생각보다 크게 나오니 주의하셔요</td>\n",
       "      <td>0</td>\n",
       "      <td>크네요 생각 크게 나오니 주의 하셔요</td>\n",
       "      <td>너무 크네요 생각 보다 크게 나오니 주의 하셔요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1</td>\n",
       "      <td>남편 선물로 사줬는데... 하루만에 벗겨졌어요.... 비추입니다</td>\n",
       "      <td>0</td>\n",
       "      <td>남편 선물 사줬는데 하루 벗겨졌어요 비추 입니다</td>\n",
       "      <td>남편 선물 사줬는데 ... 하루 만에 벗겨졌어요 .... 비추 입니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2</td>\n",
       "      <td>필터 마크가 두칸밖에안뜨요.정품맞아요</td>\n",
       "      <td>0</td>\n",
       "      <td>필터 마크 요정 맞아요</td>\n",
       "      <td>필터 마크 칸 밖에 뜨요 . 정품 맞아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>5</td>\n",
       "      <td>괜찬습니다^^ 잘쓰고있어요</td>\n",
       "      <td>1</td>\n",
       "      <td>찬습니다 잘쓰고있어요</td>\n",
       "      <td>괜 찬습니다 ^^ 잘쓰고있어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>4</td>\n",
       "      <td>빨랐어요 좋아요</td>\n",
       "      <td>1</td>\n",
       "      <td>빨랐어요 좋아요</td>\n",
       "      <td>빨랐어요 좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2</td>\n",
       "      <td>상품은 이쁜데 갓이 다 찌그러져서 왔어요 포장을 좀더 신경써주세요</td>\n",
       "      <td>0</td>\n",
       "      <td>상품 이쁜데 찌그러져서 왔어요 포장 좀더 신경 써주세요</td>\n",
       "      <td>상품 은 이쁜데 갓 찌그러져서 왔어요 포장 좀더 신경 써주세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2</td>\n",
       "      <td>이 넘 느리네요..</td>\n",
       "      <td>0</td>\n",
       "      <td>느려요</td>\n",
       "      <td>넘 느려요 ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1</td>\n",
       "      <td>앙고라 털이 엄청빠져요 옷에 다 붙어나와요</td>\n",
       "      <td>0</td>\n",
       "      <td>앙고라 빠져요 붙어 나와요</td>\n",
       "      <td>앙고라 털 엄청 빠져요 붙어 나와요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Score                                             Review  y  \\\n",
       "250      5  지방이라서 이 늦을줄 알았는데 도 빠르고 제품도 생각한것처럼 예쁘고 따갑다끔 특히나...  1   \n",
       "251      1       상품은 늘 쓰던거라 했는데요 제조일자 6개월이상 된거 보내주셨네요 기분 나쁩니다  0   \n",
       "252      1  고들빼기라 되있는데 깻잎이?? 제가 깻잎을 좋아하고 가격도 비슷하고 귀차나서 다시 ...  0   \n",
       "253      2                                         붓기 넘넘 잘빧아요  0   \n",
       "254      2                        물건을 얼려놓으면 앞 다쏠리고 힘아리가 도 없네요  0   \n",
       "255      2          신맛이 나요.. 무친지 좀 오래된듯.. 산거 후회합니다. 다 버려야 할듯   0   \n",
       "256      2  물빠짐 물빠짐 심합니다 실보프라기도 심해서 한참 제게했고 중간중간 올플림도 있어요 ...  0   \n",
       "257      5             소리도 잘나오고 가성비 정말 좋아요 드라이브 기능도 있어서 너무 만족  1   \n",
       "258      1  정전기 대박.... 기장가 긴건 내 키가 작아서라고쳐도 정전기는 왜이렇게 심한건지 ...  0   \n",
       "259      5                                     맛있어요 고급스러워보입니다  1   \n",
       "260      5  좋아요 아이 연습용 했습니다 저는 바이올린은 아예 몰라서 유튜브영상 송진바르는법 이...  1   \n",
       "261      5                                         열전달도잘괴고좋아요  1   \n",
       "262      1                           너무 크네요 생각보다 크게 나오니 주의하셔요  0   \n",
       "263      1                남편 선물로 사줬는데... 하루만에 벗겨졌어요.... 비추입니다  0   \n",
       "264      2                               필터 마크가 두칸밖에안뜨요.정품맞아요  0   \n",
       "265      5                                     괜찬습니다^^ 잘쓰고있어요  1   \n",
       "266      4                                           빨랐어요 좋아요  1   \n",
       "267      2               상품은 이쁜데 갓이 다 찌그러져서 왔어요 포장을 좀더 신경써주세요  0   \n",
       "268      2                                         이 넘 느리네요..  0   \n",
       "269      1                            앙고라 털이 엄청빠져요 옷에 다 붙어나와요  0   \n",
       "\n",
       "                                           tokenized_1  \\\n",
       "250      지방  늦을줄 알았는데  빠르고 제품 생각 예뻐요 따갑다  기사 친절하셔서 좋아요   \n",
       "251           상품 쓰던거라  했는데요 제조 일자 개월 된거 보내주셨네요 기분 나쁩니다   \n",
       "252  고들빼기 되있는데 깻잎 깻잎 좋아요하고 가격 비슷하고 나서 다시 환불 교환 요청 합...   \n",
       "253                                             붓기 잘빧아   \n",
       "254                                물건 얼려놓으면 쏠리고 아리 없네요   \n",
       "255                       신맛 무친지 오래된듯 산거 후회 합니다 버려야 할듯   \n",
       "256   빠짐 빠짐 심합니다 실보 프라 기도 심해서 한참 했고 중간 중간 있어요 가격 별로 다예   \n",
       "257                   소리 잘나오고 가성 정말 좋아요 드라이브 기능 있어서 만족   \n",
       "258  정전기 대박 기장 긴건 작아 서라고 쳐도 정전기 심한 건지 만지기만 하면 따닥따다닥...   \n",
       "259                                    맛있어요 고급스러워 보입니다   \n",
       "260  좋아요 연습  했습니다 바이올린 아예 몰라서 유튜브 영상 송진 바르는 튜닝법 검색 ...   \n",
       "261                                         열전달 괴고 좋아요   \n",
       "262                               크네요 생각 크게 나오니 주의 하셔요   \n",
       "263                         남편 선물 사줬는데 하루 벗겨졌어요 비추 입니다   \n",
       "264                                       필터 마크 요정 맞아요   \n",
       "265                                        찬습니다 잘쓰고있어요   \n",
       "266                                           빨랐어요 좋아요   \n",
       "267                     상품 이쁜데 찌그러져서 왔어요 포장 좀더 신경 써주세요   \n",
       "268                                                느려요   \n",
       "269                                     앙고라 빠져요 붙어 나와요   \n",
       "\n",
       "                                           tokenized_2  \n",
       "250  지방 이라서  늦을줄 알았는데  빠르고 제품 생각 처럼 예뻐요 따갑다 끔 특히  기...  \n",
       "251     상품 은 늘 쓰던거라  했는데요 제조 일자 6 개월 된거 보내주셨네요 기분 나쁩니다  \n",
       "252  고들빼기 되있는데 깻잎 ?? 깻잎 좋아요하고 가격 비슷하고 귀 나서 다시 환불 이나...  \n",
       "253                                         붓기 넘 넘 잘빧아  \n",
       "254                                물건 얼려놓으면 쏠리고 아리 없네요  \n",
       "255            신맛 나요 .. 무친지 오래된듯 .. 산거 후회 합니다 . 버려야 할듯  \n",
       "256  빠짐 빠짐 심합니다 실보 프라 기도 심해서 한참 했고 중간 중간 올 플 림 있어요 ...  \n",
       "257                소리 잘나오고 가성 정말 좋아요 드라이브 기능 있어서 너무 만족  \n",
       "258  정전기 대박 .... 기장 긴건 내 키 작아 서라고 쳐도 정전기 는 이렇게 심한 건...  \n",
       "259                                    맛있어요 고급스러워 보입니다  \n",
       "260  좋아요 연습 용  했습니다 는 바이올린 은 아예 몰라서 유튜브 영상 송진 바르는 법...  \n",
       "261                                       열전달 잘 괴고 좋아요  \n",
       "262                         너무 크네요 생각 보다 크게 나오니 주의 하셔요  \n",
       "263             남편 선물 사줬는데 ... 하루 만에 벗겨졌어요 .... 비추 입니다  \n",
       "264                             필터 마크 칸 밖에 뜨요 . 정품 맞아요  \n",
       "265                                   괜 찬습니다 ^^ 잘쓰고있어요  \n",
       "266                                           빨랐어요 좋아요  \n",
       "267                 상품 은 이쁜데 갓 찌그러져서 왔어요 포장 좀더 신경 써주세요  \n",
       "268                                           넘 느려요 ..  \n",
       "269                                앙고라 털 엄청 빠져요 붙어 나와요  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[250:270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score          0\n",
      "Review         0\n",
      "y              0\n",
      "tokenized_1    0\n",
      "tokenized_2    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 199572 entries, 0 to 199999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Score        199572 non-null  int64 \n",
      " 1   Review       199572 non-null  object\n",
      " 2   y            199572 non-null  int64 \n",
      " 3   tokenized_1  199572 non-null  object\n",
      " 4   tokenized_2  199572 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM + GridSearchCV + tokenizer_1\n",
    "* countervectorizer\n",
    "* GridSearchCV\n",
    "* Tokenizer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['y']\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(df['tokenized_1'], y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df = 3, ngram_range=(1,2), tokenizer = tokenizer)\n",
    "X_train_tf = vect.fit_transform(X_train_texts)\n",
    "X_test_tf = vect.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist_DTM_tk1 = [word for word, number in sorted(vect.vocabulary_.items(), key = lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "{'C': 0.8} 0.8947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(random_state = 0, solver = 'liblinear', max_iter = 1000)\n",
    "params = { 'C': [0.6, 0.8, 1 ,3.5, 4.5 ] }\n",
    "grid_cv = GridSearchCV(lr , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
    "grid_cv.fit(X_train_tf , y_train)\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_DTM_tk1 = grid_cv.best_estimator_\n",
    "y_pred = best_estimator_DTM_tk1.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n",
      "Precision : 0.905\n",
      "Recall : 0.891\n",
      "F1 : 0.898\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('DTM_tokenizer1_gridsearch_done_improved.pickle','wb') as fw:\n",
    "    pickle.dump(best_estimator_DTM_tk1, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)\n",
      "맛있어요(2.965)\n",
      "튼튼합니다(2.831)\n",
      "만족해요(2.626)\n",
      "잘쓰고있어요(2.510)\n",
      "좋아요(2.458)\n",
      "최고(2.399)\n",
      "튼튼하네요(2.390)\n",
      "존맛(2.305)\n",
      "예쁘네요(2.300)\n",
      "편(2.288)\n",
      "예뻐요(2.262)\n",
      "좋아요하시네요(2.229)\n",
      "괜찮네요(2.225)\n",
      "빠르고(2.215)\n",
      "귀엽다(2.214)\n",
      "잘썼어요(2.171)\n",
      "딱이에요(2.156)\n",
      "편합니다(2.134)\n",
      "튼튼하고(2.107)\n",
      "고급스러워요(2.103)\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_estimator_DTM_tk1.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:20]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist_DTM_tk1[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)\n",
      "최악(-3.748)\n",
      "실망(-3.392)\n",
      "비추(-3.298)\n",
      "다시는(-2.999)\n",
      "약(-2.759)\n",
      "좋아요 좋아요(-2.741)\n",
      "맛있어요 맛있어요(-2.708)\n",
      "맛없어요(-2.683)\n",
      "심하네요(-2.660)\n",
      "그래요(-2.545)\n",
      "환불(-2.522)\n",
      "별로(-2.454)\n",
      "안됩니다(-2.411)\n",
      "느려요(-2.383)\n",
      "떨어집니다(-2.328)\n",
      "불친절(-2.300)\n",
      "안좋아요(-2.292)\n",
      "불편합니다(-2.280)\n",
      "반품(-2.279)\n",
      "안됨(-2.259)\n"
     ]
    }
   ],
   "source": [
    "print('\\n부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-20:][::-1]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist_DTM_tk1[word_num], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF + GridSearchCV + tokenizer_1\n",
    "* TFIDF\n",
    "* GridSearchCV\n",
    "* Tokenizer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df = 3, max_df = 0.9, tokenizer = tokenizer)\n",
    "tfidf_vectorizer.fit(X_train_texts)\n",
    "tfidf_matrix_train = tfidf_vectorizer.transform(X_train_texts)\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist_TFIDF_tk1 = [word for word, number in sorted(tfidf_vectorizer.vocabulary_.items(), key = lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "{'C': 3.5} 0.8967\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 0, solver = 'liblinear', max_iter = 1000)\n",
    "params = { 'C': [0.6, 0.8, 1 ,3.5, 4.5 ] }\n",
    "grid_cv = GridSearchCV(lr , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
    "grid_cv.fit(tfidf_matrix_train , y_train)\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_TFIDF_tk1 = grid_cv.best_estimator_\n",
    "y_pred = best_estimator_TFIDF_tk1.predict(tfidf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n",
      "Precision : 0.905\n",
      "Recall : 0.893\n",
      "F1 : 0.899\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TFIDF_tokenizer1_gridsearch_done_improved.pickle','wb') as fw:\n",
    "    pickle.dump(best_estimator_TFIDF_tk1, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)\n",
      "좋아요(10.449)\n",
      "맛있어요(10.234)\n",
      "만족해요(8.684)\n",
      "예뻐요(8.546)\n",
      "최고(7.722)\n",
      "빠르고(7.312)\n",
      "튼튼하고(6.832)\n",
      "만족(6.322)\n",
      "편(6.097)\n",
      "걱정 했는데(5.774)\n",
      "편하고(5.654)\n",
      "괜찮네요(5.567)\n",
      "귀엽다(5.538)\n",
      "강추(5.441)\n",
      "튼튼합니다(5.404)\n",
      "항상(5.383)\n",
      "좋았습니다(5.254)\n",
      "있어서 좋아요(5.214)\n",
      "빨랐고(5.109)\n",
      "듭니(5.085)\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_estimator_TFIDF_tk1.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:20]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist_TFIDF_tk1[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)\n",
      "실망(-13.225)\n",
      "반품(-11.114)\n",
      "별로(-11.026)\n",
      "최악(-10.417)\n",
      "비추(-9.335)\n",
      "다시는(-8.819)\n",
      "그렇다(-7.887)\n",
      "환불(-7.631)\n",
      "약(-6.835)\n",
      "엉망(-6.493)\n",
      "불편(-6.381)\n",
      "안좋아요(-6.311)\n",
      "안됩니다(-6.284)\n",
      "심하네요(-6.272)\n",
      "버렸어요(-6.209)\n",
      "맛없어요(-5.979)\n",
      "불편합니다(-5.869)\n",
      "떨어지네요(-5.852)\n",
      "불량(-5.764)\n",
      "떨어집니다(-5.758)\n"
     ]
    }
   ],
   "source": [
    "print('\\n부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-20:][::-1]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist_TFIDF_tk1[word_num], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM + GridSearchCV + tokenizer_2\n",
    "* countervectorizer\n",
    "* GridSearchCV\n",
    "* Tokenizer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(df['tokenized_2'], y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect2 = CountVectorizer(min_df = 3, ngram_range=(1,2), tokenizer = tokenizer)\n",
    "X_train_tf = vect2.fit_transform(X_train_texts)\n",
    "X_test_tf = vect2.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist_DTM_tk2 = [word for word, number in sorted(vect2.vocabulary_.items(), key = lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "{'C': 0.6} 0.9111\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 0, solver = 'liblinear', max_iter = 1000)\n",
    "params = { 'C': [0.6, 0.8, 1 ,3.5, 4.5 ] }\n",
    "grid_cv = GridSearchCV(lr , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
    "grid_cv.fit(X_train_tf , y_train)\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n",
      "Precision : 0.915\n",
      "Recall : 0.910\n",
      "F1 : 0.912\n"
     ]
    }
   ],
   "source": [
    "best_estimator_DTM_tk2 = grid_cv.best_estimator_\n",
    "y_pred = best_estimator_DTM_tk2.predict(X_test_tf)\n",
    "\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DTM_tokenizer2_gridsearch_done_improved.pickle','wb') as fw:\n",
    "    pickle.dump(best_estimator_DTM_tk2, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)\n",
      "맛있어요(2.674)\n",
      "만족해요(2.453)\n",
      "튼튼합니다(2.296)\n",
      "최고(2.171)\n",
      "좋아요(2.154)\n",
      "잘쓰고있어요(2.108)\n",
      "빠르고(2.075)\n",
      "잘 왔어요(2.074)\n",
      "예뻐요(2.021)\n",
      "괜찮네요(1.991)\n",
      "예쁘네요(1.923)\n",
      "만족(1.909)\n",
      "튼튼하고(1.886)\n",
      "튼튼하네요(1.881)\n",
      "편합니다(1.880)\n",
      "좋았습니다(1.862)\n",
      "편하다(1.850)\n",
      "딱이에요(1.841)\n",
      "좋아요하시네요(1.811)\n",
      "촉촉(1.807)\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_estimator_DTM_tk2.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:20]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist_DTM_tk2[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)\n",
      "최악(-3.353)\n",
      "실망(-3.069)\n",
      "비추(-2.724)\n",
      "다시는(-2.653)\n",
      "좋아요 좋아요(-2.469)\n",
      "그래요(-2.245)\n",
      "맛있어요 맛있어요(-2.202)\n",
      "별로(-2.171)\n",
      "약(-2.133)\n",
      "심하네요(-2.094)\n",
      "떨어져요(-2.084)\n",
      "불만족(-2.073)\n",
      "좋아요 아주(-2.047)\n",
      "환불(-2.042)\n",
      "맛없어요(-2.023)\n",
      "안좋아요(-2.010)\n",
      "안됩니다(-1.997)\n",
      "불편(-1.993)\n",
      "반품(-1.978)\n",
      "안됨(-1.971)\n"
     ]
    }
   ],
   "source": [
    "print('\\n부정적인 단어 Top 20 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-20:][::-1]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist_DTM_tk2[word_num], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF + GridSearchCV + tokenizer_2\n",
    "* TFIDF\n",
    "* GridSearchCV\n",
    "* Tokenizer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer2 = TfidfVectorizer(ngram_range=(1,2), min_df = 3, max_df = 0.9, tokenizer = tokenizer)\n",
    "tfidf_vectorizer2.fit(X_train_texts)\n",
    "tfidf_matrix_train = tfidf_vectorizer2.transform(X_train_texts)\n",
    "tfidf_matrix_test = tfidf_vectorizer2.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist_TFIDF_tk2 = [word for word, number in sorted(vect2.vocabulary_.items(), key = lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "{'C': 3.5} 0.9125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(random_state = 0, solver = 'liblinear', max_iter = 1000)\n",
    "params = { 'C': [0.6, 0.8, 1 ,3.5, 4.5 ] }\n",
    "grid_cv = GridSearchCV(lr , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
    "grid_cv.fit(tfidf_matrix_train, y_train)\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n",
      "Precision : 0.884\n",
      "Recall : 0.931\n",
      "F1 : 0.907\n"
     ]
    }
   ],
   "source": [
    "best_estimator_TFIDF_tk2 = grid_cv.best_estimator_\n",
    "y_pred = best_estimator_TFIDF_tk2.predict(X_test_tf)\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('TFIDF_tokenizer2_gridsearch_done_improved.pickle','wb') as fw:\n",
    "    pickle.dump(best_estimator_TFIDF_tk2, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)\n",
      "좋아요(14.662)\n",
      "맛있어요(11.059)\n",
      "만족해요(9.158)\n",
      "예뻐요(8.888)\n",
      "최고(8.511)\n",
      "빠르고(7.974)\n",
      "^^(7.707)\n",
      "만족(7.237)\n",
      "ㅎㅎ(7.068)\n",
      "!(6.849)\n",
      "~^^(6.684)\n",
      "튼튼하고(6.457)\n",
      "편(5.974)\n",
      "괜찮네요(5.902)\n",
      "너무 예뻐요(5.853)\n",
      "항상(5.837)\n",
      "확실히(5.750)\n",
      "편하고(5.536)\n",
      ":)(5.504)\n",
      "없이 잘(5.492)\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_estimator_TFIDF_tk2.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 20 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:20]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist_TFIDF_tk2[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 단어 Top 10 (낮은 평점과 상관관계가 강한 단어들)\n",
      "실망(-12.800)\n",
      "별로(-11.660)\n",
      "반품(-10.577)\n",
      "최악(-10.169)\n",
      "비추(-9.050)\n",
      "그렇다(-8.953)\n",
      "다시는(-8.436)\n",
      "ㅡㅡ(-7.543)\n",
      "불편(-7.196)\n",
      "환불(-6.941)\n",
      "좋아요 좋아요(-6.888)\n",
      "빠르고 좋아요(-6.802)\n",
      "안좋아요(-6.725)\n",
      "그래요(-6.526)\n",
      "불량(-6.373)\n",
      "못(-6.363)\n",
      "마세요(-6.294)\n",
      "떨어져요(-6.152)\n",
      "엉망(-6.012)\n",
      "약(-5.981)\n"
     ]
    }
   ],
   "source": [
    "print('\\n부정적인 단어 Top 10 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-20:][::-1]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist_TFIDF_tk2[word_num], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTM + 하이퍼파라미터 튜닝 + 유의어 일원화 보완(보완전) + 명사/형용사/동사만 추출\n",
    "* accuracy: 0.90 (0.90)\n",
    "* Precision : 0.905 (0.905)\n",
    "* Recall : 0.891 (0.892)\n",
    "* F1 : 0.898 (0.898)\n",
    "\n",
    "### TFIDF + 하이퍼파라미터 튜닝 + 유의어 일원화 보완(보완전)+ 명사/형용사/동사만 추출\n",
    "* accuracy: 0.90(0.90)\n",
    "* Precision : 0.905(0.907)\n",
    "* Recall : 0.893(0.894)\n",
    "* F1 : 0.899(0.900)\n",
    "\n",
    "### DTM + 하이퍼파라미터 튜닝 + 유의어 일원화 보완(보완전)+ 형태소만 추출\n",
    "* accuracy: 0.91(0.91)\n",
    "* Precision : 0.915(0.914)\n",
    "* Recall : 0.910(0.910)\n",
    "* F1 : 0.912 (0.912)\n",
    "\n",
    "### TFIDF + 하이퍼파라미터 튜닝 + 유의어 일원화 보완(보완전)+ 형태소만 추출\n",
    "* accuracy: 0.90(0.90)\n",
    "* Precision : 0.884(0.883)\n",
    "* Recall : 0.931(0.931)\n",
    "* F1 : 0.907(0.906)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('ds_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8980de4a27bf89e986bf71fe1fbb5d572934705242a5da409cea5b4049808f61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
