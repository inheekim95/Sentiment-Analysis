{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/naver_shopping.txt\", sep = '\\t', encoding = 'utf-8', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
    "stopwords.append('배송')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['rating', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_to_label(rating):\n",
    "    if rating >=4 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['y'] = df['rating'].apply(lambda x: rating_to_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('택배', 'Noun'),\n",
       " ('가', 'Josa'),\n",
       " ('엉망', 'Noun'),\n",
       " ('이네', 'Josa'),\n",
       " ('용', 'Noun'),\n",
       " ('저희', 'Modifier'),\n",
       " ('집', 'Noun'),\n",
       " ('밑', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('층', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('말', 'Noun'),\n",
       " ('도', 'Josa'),\n",
       " ('없이', 'Adverb'),\n",
       " ('놔두고가고', 'Verb')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = Okt()\n",
    "line = tagger.pos(df['text'][1])\n",
    "line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessed(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]')\n",
    "    result = hangul.sub('', text)\n",
    "    okt = Okt()\n",
    "    Okt_morphs = okt.pos(result)\n",
    "    words = []\n",
    "\n",
    "    for word, pos in Okt_morphs:\n",
    "        if pos == 'Adjective' or pos == 'Verb' or pos == 'Noun':\n",
    "            if len(word) > 1 and word not in stopwords:\n",
    "                words.append(word)\n",
    "\n",
    "    words_str = ' '.join(words)\n",
    "    return words_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_texts = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    tokenized_review = text_preprocessed(df.loc[idx, 'text'])\n",
    "    X_texts.append(tokenized_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = X_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아주 바지 정말 구매 가격 대박 바느질 조금 가성 최고'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = df['tokenized'][2]\n",
    "words_str = ' '.join(list)\n",
    "words_str  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200000it [00:07, 25040.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['배공',\n",
       " '택배 엉망',\n",
       " '아주 바지 정말 구매 가격 대박 바느질 조금 가성 최고',\n",
       " '선물 전달 상품 머그컵 당황 바로 누락 확인 바로 선물 큰일 다시 생각',\n",
       " '민트 색상 손잡이 도로 사용']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "list_to_string = []\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    list_to_string.append(' '.join(df.loc[idx, 'tokenized']))\n",
    "\n",
    "list_to_string[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "      <td>1</td>\n",
       "      <td>배공</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "      <td>0</td>\n",
       "      <td>택배 엉망</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>아주 바지 정말 구매 가격 대박 바느질 조금 가성 최고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "      <td>0</td>\n",
       "      <td>선물 전달 상품 머그컵 당황 바로 누락 확인 바로 선물 큰일 다시 생각</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "      <td>1</td>\n",
       "      <td>민트 색상 손잡이 도로 사용</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                               text  y  \\\n",
       "0       5                                            배공빠르고 굿  1   \n",
       "1       2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고  0   \n",
       "2       5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...  1   \n",
       "3       2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...  0   \n",
       "4       5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ  1   \n",
       "\n",
       "                                 tokenized  \n",
       "0                                       배공  \n",
       "1                                    택배 엉망  \n",
       "2           아주 바지 정말 구매 가격 대박 바느질 조금 가성 최고  \n",
       "3  선물 전달 상품 머그컵 당황 바로 누락 확인 바로 선물 큰일 다시 생각  \n",
       "4                          민트 색상 손잡이 도로 사용  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized'] = list_to_string\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/naver_shopping_tokenized.csv', sep = \",\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['y'].values.tolist()\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(df['tokenized'], y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 3, ngram_range=(1, 2))\n",
    "X_train_tf = vect.fit_transform(X_train_texts)\n",
    "X_test_tf = vect.transform(X_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist = [word for word, number in sorted(vect.vocabulary_.items(), key=lambda x:x[1])]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(random_state = 0)\n",
    "lr.fit(X_train_tf, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.78\n",
      "Precision : 0.742\n",
      "Recall : 0.850\n",
      "F1 : 0.792\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y']\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(df['tokenized'], y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df = 3, max_df = 0.9)\n",
    "tfidf_vectorizer.fit(X_train_texts)\n",
    "tfidf_matrix_train = tfidf_vectorizer.transform(X_train_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeri\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression(random_state = 0)\n",
    "lr_tfidf.fit(tfidf_matrix_train, y_train)\n",
    "\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(X_test_texts)\n",
    "y_pred = lr_tfidf.predict(tfidf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.78\n",
      "Precision : 0.750\n",
      "Recall : 0.835\n",
      "F1 : 0.790\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM 기준으로 하이퍼파라미터 튜닝 전 성능 평가\n",
    "* accuracy: 0.78\n",
    "* Precision : 0.742\n",
    "* Recall : 0.850\n",
    "* F1 : 0.792\n",
    "\n",
    "## TF-IDF 기준으로 하이퍼파라미터 튜닝 전 성능 평가\n",
    "* accuracy: 0.78\n",
    "* Precision : 0.750\n",
    "* Recall : 0.835\n",
    "* F1 : 0.790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8980de4a27bf89e986bf71fe1fbb5d572934705242a5da409cea5b4049808f61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
